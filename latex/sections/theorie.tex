\documentclass[../main]{subfiles}

\begin{document}


Der Themenbereich des Machinellen Lernens beschäftigt sich mit Algorithmen und mathematischen Modellen, welche von selber lernen, Probleme zu loesen.
Hierzu werden keine expliziten Instruktionen fest einprogrammiert (engl.: hard coding), sondern das Modell wird trainiert und optimiert sich von selbst.
Dabei wird das Modell mit Trainingsdaten befuettern, mithilfe dessen eine Korrelation zwischen den Inputdaten und den Outputdaten erlernt werden soll.
Der Zusammenhang der Daten wird von den Modellen verallgemeinert und das Modell kann dann Vorhersagen fuer neue Daten machen. 

\subsection{Daten}

Der Trainingsdatensatz beinhaltet gewisse \textbf{Attribute}, die Merkmalstypen der Inputdaten.
Die \textbf{Features} sind dann die spezifischen Werte der Attribute eines Trainingssample.
Die sogenannten \textbf{Labels} sind die erwarteten Outputs, welche der Algorithmus vorherzusagen hat.
Diese Vorhersagen werden mit den Labels abgeglichen und so bewertet.
Anhand der Bewertungen wird dann eine Optimierung des Modells vorgenommen.
Unter korrekten Bedingungen (keine Ueberanpassung) findet kein Auswendiglernen der Trainingsdaten statt,
sondern ein Generalisieren des Zusammenhangs, anhand von Mustern und Gesetzmassigkeiten.

Um eine Endgueltige Bewertung des Modells durchzufuehren, wird ein Testdatensatz, welcher nicht Teil des Trainingsdatensatz ist, genutzt um Vorhersagen zu machen.
Dies garantiert, dass kein Auswendiglernen moeglich ist.

Die Inputs/Features werden in einem Vektor $\vec{x}=(x_1,x_2,...,x_n)^T$ und die Outputs/Vohersagen in einem Vektor $\vec{y}=(y_1,y_2,...,y_m)^T$ zusammengefasst.
Das gleiche macht man mit den Labels, wobei diese mit $\vec{\hat{y}}=(\hat{y}_1,\hat{y_2},...,\hat{y}_m)^T$ bezeichnet werden.
\par \medskip
Am Beispiel eines Datensatz, welcher fuer Bilderkennung von Hunden und Katzen genutzt wird, werden diese Begriffe verdeutlicht.
Die Inputdaten sind die Fotos von Hunden und Katzen. Deren Attribute sind die moeglichen RGB-Farbenwerte (drei Zahlen, welche von 0 bis 255 reichen).
Die Features sind die spezifischen RGB-Werte fuer ein Bild. Die Outputdaten sind die Labels, welche in diesem Fall angeben, ob ein Hund oder eine Katze auf dem Bild gezeigt wird.
Dies wird meistens mit einer One-Hot-Kodierung bzw. einem One-Hot-Vektor gemacht. Jeder Labelart wird eine eigene Vektorkomponente zugewiesen. Falls das Label aktiv ist, ist die Komponent 1 ansonsten 0. Also Hund koennte als $\vec{l}_H=(1,0)^T$ reprasentiert werden und Katze als $\vec{l}_K=(0,1)^T$.

\begin{figure}[h!]
    \centering
    \begin{tikzpicture}[node distance=5cm,auto]
        
    \end{tikzpicture}
    
    \caption{eine Veranschaulichung eines Machine Learning Modells}
\end{figure}

\subsection{Modelle (allgemein)}
Ein Modell ist eine differenzierbare mathematische Funktion $\mathit{f}\colon \mathbb{R}^n \to \mathbb{R}^m$ welche die Inputs auf die Outputs abbildet $\vec{y}=\mathit{f}(\vec{x})$.
Im Zusammenhang mit Wertevorhersagen spricht man von einem Regressionsmodell.
Das Verhalten dieses Modells wird bestimmt durch seine \textbf{Modellparameter} $\phi_1, \phi_2, ...$.
Das Ziel ist es die Modellparameter so einzustellen, dass die Vorherrsagen $\vec{y}$ besser mit den Labels $\vec{\hat{y}}$ uebereinstimmen.
Dies wird iterativ gemacht, indem immer wieder leichte Anpassungen an den Parametern vorgenommen werden, bis sie das gewunschte Resultat liefern. 

Das wohl einfachste Regressionsmodell ist eine Regressionsgerade. Diese ist angemessen, falls ein einfacher linearen Zusammenhang zwischen den Features und den Labels besteht.
$y=\phi_1x + \phi_0$. Nun muessten nur noch $\phi_0$ und $\phi_1$ bestimmt werden. 

Neben den gelernten Parametern, gibt es auch noch sogenannte \textbf{Hyperparameter}.
Diese koennen nicht erlernt werden, sondern muessen manuell vor dem Training gewaehlt werden und koennen den Lernvorgang erheblich beeinflussen.
\par
\medskip
Es gibt die verschiedensten Modelle. Einige der bekanntesten sind: Support Vector Machines, Evolutionäre Algorithmen, und Künstliche Neuronale Netze.
Diese Arbeit wird sich vorwiegend auf Neuronale Netze beziehen.

BEISPIELMODELL (in der Art: Note anhand Lernstunden vorhersagen)

\subsection{Training}
\subsubsection{Kostenfunktionen}
Einsicht ist der erste Schritt zur Besserung. Das gilt auch beim Machine Learning, deshalb muss beim Training zuerst die Genauigkeit des Models bewertet werden.
Dafuer gibt es sogennante Kosten-, Verlust- oder Fehlerfunktionen. Sie soll ein Mass fuer die Abweichung des Outputs $\vec{y}$ vom Label $\vec{\hat{y}}$ sein.
\par\medskip
Die Fehler der einzlnen Outputs $c_i$ werden aufsummiert um den Fehler C einer gesamten Vorhersage zu berechnen. \ref{eq:errorfunc}\\
Der Fehler eines Datensatzen $\bar{C}$ ergibt sich aus dem arithmetischen Mittel der Vorhersagen-Fehler. \ref{eq:meanerrorfunc}\\
%
\begin{minipage}[t]{0.5\textwidth}
    \centering
    \begin{equation}\label{eq:errorfunc}
        C(\vec{y},\vec{\hat{y}})=\displaystyle\sum_{i=1}^{m} c(y_i, \hat{y}_i)
    \end{equation}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
    \centering
    \begin{equation}\label{eq:meanerrorfunc}
        \bar{C} = \frac{1}{p}\displaystyle\sum_{j=1}^{p} C\Big(\vec{y}_j,\vec{\hat{y}}_j\Big)
    \end{equation}
\end{minipage}

%
Eine Kostenfunktion $c(y_i,\hat{y}_i)$ sollte folgende Eigenschaften aufweisen:
\begin{itemize}
    \item{$c$ ist $0$, wenn $y = \hat{y}$}
    \item{$c$ waechst mit $|\vec{y}-\vec{\hat{y}}|$}
    \item{$C$ ist nach jedem $y_n$ partiell differenzierbar}
\end{itemize}

Eine beliebte Kostenfunktion ist die ``Mittlere quadratische Abweichung'' (engl.: mean squared error).\\
$\displaystyle C_{MSE} = \frac{1}{2n}\sum_{i=1}^{n}(\hat{y}_i - y_i)^2 = \frac{1}{2n}(\vec{\hat{y}} - \vec{y})^2$
Sie erfuellt alle anforderungen, denn:
Sie ist $0$ falls $y=\hat{y}$. Sie ist proportional zu $(\hat{y}-y)^2$ und ihre Ableitung nach $y$ lautet: $C'=\frac{1}{n}(\hat{y}-y)$


\subsubsection{Gradientenverfahren (engl.: Gradient descent)}
Unser Modell ist dann am besten, wenn die Fehlerfunktion am kleinsten ist.
Deshalb gilt es nun ein Optimierungsproblem zu loesen, um das Modell zu trainieren, konkret: Die Fehlerfunktion $C$ muss minimiert werden.
Hierbei muss die Funktion $C$ nicht mehr in Abhangigkeit der Outputs und Labels betrachtet werden, sondern stattdessen in Abhangigkeit von den Modellparamtern. $C(\phi_1, \phi_2, \cdots, \phi_n)$, denn diese sollen angepasst werden, um das Modell zu verbessern.
Hierfuer verwendet man das sogennante \textbf{Gradientenverfahren}.
\footnote{
    Im Gymnasium lernt man die lokalen Extrema (inkl. lokalen Minimas) zu bestimmen, indem man die erste Ableitung $f'$ gleich null setzt.
    Dies ist hier nicht moeglich, da die Funktion $C'(\phi_1,\phi_2, \cdots, \phi_n)$ deutlich zu komplex ist, um die Nullstellen zu bestimmen. Deshalb braucht man das Gradientenverfahren.
}\par
\medskip
Allgemein koennen mithilfe des Gradientenverfahrens Funkionen $f(x_1, x_2, \cdots, x_n)$ vom Typ $\mathbb{R}^n \to \mathbb{R}$ (wie z.B. die Fehlerfunktion) minimiert werden.
Dies beschieht, in dem ein Startpunkt (Ortsvektor) $\vec{p}_0$, dessen Komponenten den Input von $f$ darstellt, gewaehlt wird.
Nun werden iterativ neue Punkte $\vec{p_z}$ gesucht, welche immer naeher beim lokalen Minimun liegen, also Punkte die den Funktionswert $f(\vec{p}_z)$ immer kleiner werden lassen.
Dies wird durchgeführt, bis der Punkt genug nahe beim lokalen Minimun ist.
\par
\medskip
Dafuer muss ein Vektor $\vec{b}_z$ bestimmt werden, welcher auf den Punkt $\vec{p}_z$ draufaddiert einen neuen Punkt $\vec{p}_{z+1}$ bildet,
bei dem der Funktionswert $f(\vec{p}_{z+1})$ kleiner ist als der von $f(\vec{p}_z)$.
Dies geschieht am effizientesten, wenn $\vec{b}_z$ in die Richtung der staerksten Funktionswertabnahme zeigt.

Hierzu braucht man den sogennanten \textbf{Gradient} $\vec{\nabla}$, wofür man wiederum partielle Ableitungen braucht.\\

\tikzstyle{mybox} = [draw=red, fill=blue!20, very thick, rectangle, rounded corners, inner sep=10pt, inner ysep=20pt]
 \tikzstyle{fancytitle} = [fill=red, text=white]

\noindent \begin{tikzpicture}
    \node [mybox] (box) {%
            \begin{minipage}{1.0\textwidth}

                Partielle Ableitungen sind eine Erweiterung der ''normalen`` Ableitungen auf multidimensionale Funktionen $f(x_1,\cdots,x_n)$.
                Man leitet dabei nur nach einem Parameter $x_i$ ab und betrachtet die restlichen Argumente als Konstanten.
                Es gelten die gleichen Ableitungsregeln wie bei der nicht-partiellen Ableitung.
                Die partielle Ableitung einer Funktion $f(x_1,\cdots,x_n)$ bezueglich der Variabel $x_i$ in einem Punkt $\vec{a}=(a_1,\cdots,a_n)^T$ ist analog zur ''normalen`` Ableitung folgendermassen definiert:
                \par\medskip
                $\displaystyle\frac{\partial f}{\partial x_i}(\vec{a}) := \lim_{h \to 0} \frac{f(a_1,\cdots,a_i + h,\cdots,a_n)-f(a_1,\cdots,a_i,\cdots,a_n)}{h}$
                \par\medskip
                Geometisch ist dies die Steigung der Tangente im Punkt $\vec{a}$ in Richtung der Achse des Parametern $x_i$, nach dem man ableitet.


            \end{minipage}

    };
    \node[fancytitle,right=10pt] at (box.north west) {Partielle Ableitungen};

\end{tikzpicture}

\noindent \begin{tikzpicture}
     \node [mybox] (box) {%
             \begin{minipage}{1.0\textwidth}

             Der Gradient $\vec{\nabla}$ ist ein Differentialoperator, welcher ein Skalarfeld auf ein Vektorfeld (das sogennante Gradientenfeld) abbildet.\\
             Dabei fasst man alle partiellen Ableitungen einer Funktion $f$ in einem Vektor zusammen.
             Der Gradient $\vec{\nabla}f(\vec{p})$ einer Funktion $f$ in einem Punkt $\vec{p}$ ist der Vektor, welcher in die Richtung des steilsten Anstiegs von $f$ zeigt.
             Seine Magnitude gibt die Staerke des Anstiegs an.
             \par\medskip
                $\displaystyle grad(f)=\vec{\nabla}f=
                \begin{pmatrix}
                    \frac{\partial f}{\partial x_1} \\
                    \vdots \\
                    \frac{\partial f}{\partial x_n} \\
                \end{pmatrix}$



             \end{minipage}
     };
    \node[fancytitle,right=10pt] at (box.north west) {Gradient};
\end{tikzpicture}



Da der Gradient in die Richtung des steilsten Anstiegs zeigt, sollte der Vektor $\vec{b}_z$ in die Richtung des negierten Gradient der Funktion $f$ im Punkt $\vec{p}_z$ zeigen.
Also kann jetzt das iterative Annahern an das lokalen Minimums so beschrieben werden:\\
\begin{equation}\label{eq:gradientdescent}
    \displaystyle\vec{p}_{z+1} = \vec{p}_z - \eta \cdot \vec{\nabla} \mathit{f}(\vec{p}_z)
\end{equation}

Beim Gradientenverfahren konvergiert der Punkt $\vec{p}_z$ zu einem belibigen \textit{lokalen} Minimum, abhängig davon wie der Startpunkt $\vec{p}_0$ gewaehlt wurde.
Da dieser meist zufaellig bestimmt wird, ist es eine Glückssache ein sehr tiefes Minimum zu finden.
Nach dem erfolgreichen Gradientenabstieg bedeutet dass fuer unser Modell, dass die Komponenten von $\vec{p}_n$ optimalen Modellparamteter, welche den Fehler des Modells
minimieren, darstellen. Somit wurde das Modell erfolgreich trainiert.

Die sogennante \textbf{Lernrate} $\eta$ aus Gleichung (\ref{eq:gradientdescent}) ist ein Hyperparameter.
Sie ist ein positiver Proportionalitatsfaktor, welcher die Schrittgroesse des Gradientenabstieg bestimmt. Sie muss je nach zu minimierender Funktion anderst gewaehlt werden.
Dabei hilft nur ausporbieren. Falls $\eta$ nicht gut gewahelt wurde, gibt es Probleme beim Training:
\begin{itemize}
    \item{Falls $\eta$ zu klein ist, verlaueft das Trainings unnotig langsam und braucht sehr lange.
        Ausserdem kann es passieren, dass man bei einem Sattelpunkt oder einem hohen lokalen Minimum stecken bleibt.}

    \item{Falls $\eta$ zu gross ist, passiert es, dass man ueber das lokale Minimum hinaus schiesst und nur darum herum sprint.}

\end{itemize}
\begin{figure}[h!]
    \caption{Visualiesierung verschiedener Lernraten}
\end{figure}

\par\medskip

\subsubsection{Stochastic Gradient Descent}

\subsection{Neural Networks}
\subsubsection{Backpropagation}
\subsubsection{Feedforward Neural Network}
\subsubsection{Convolutional Neural Networks}
\subsubsection{Autoencoder}
\subsubsection{Variational Autoencoder?}
\subsubsection{Detangled Autoencoder?}


\end{document}
